{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d7489dbb-2dcb-46fb-8efe-a5b005bac863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU:  1\n",
      "GPU Name:  NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torchaudio \n",
    "import torch\n",
    "\n",
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "484785d8-5d1d-4558-a27c-657bc703e8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC,Wav2Vec2Processor,Wav2Vec2FeatureExtractor,Wav2Vec2CTCTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d60de039-d958-4a88-9c0d-4e764befab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(\"E:/lipyantrak/trained_models/wav2vec0.8dropout\").to(\"cuda\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"E:/lipyantrak/processor/wav2vec0.8dropout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1c1fd971-51bb-418d-8f0c-73e1caaef1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentLargeArray(inputTensor,chunksize=200000):\n",
    "    # print(inputTensor)\n",
    "    list_of_segments = []\n",
    "    tensor_length = inputTensor.shape[1]\n",
    "    for i in range(0,tensor_length+1,chunksize):\n",
    "        list_of_segments.append(inputTensor[:,i:i+chunksize])\n",
    "    return list_of_segments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8a5f3317-34a1-49a7-9b1d-13de1b8db381",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"E:/lipyantrak/csv_files/test.csv\"\n",
    "test_data=pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "91c722db-378e-4428-83e3-ebc778174702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "def count_lines_and_generate_one_random_number(csv_file_path):\n",
    "    \"\"\"\n",
    "    Count the number of lines in a CSV file and generate one random number within that range.\n",
    "\n",
    "    Args:\n",
    "    - csv_file_path (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Total line count and a single random number (or None if the file is empty).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize line count\n",
    "        line_count = 0\n",
    "\n",
    "        # Open the file and count the lines\n",
    "        with open(csv_file_path, 'r', encoding='utf-8') as file:\n",
    "            reader = csv.reader(file)\n",
    "            for _ in reader:\n",
    "                line_count += 1\n",
    "\n",
    "        print(f\"Total number of lines in the CSV file: {line_count}\")\n",
    "\n",
    "        # Generate a single random number within the range of lines\n",
    "        if line_count > 0:\n",
    "            random_line_number = random.randint(1, line_count)\n",
    "            print(f\"Random line number: {random_line_number}\")\n",
    "            return line_count, random_line_number\n",
    "        else:\n",
    "            print(\"The file is empty. Cannot generate a random number.\")\n",
    "            return line_count, None\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at '{csv_file_path}' was not found.\")\n",
    "        return 0, None\n",
    "\n",
    "# Example Usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "78392e75-048f-4b1c-81b9-6be4ff2b87fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of lines in the CSV file: 272\n",
      "Random line number: 41\n"
     ]
    }
   ],
   "source": [
    "random_number = count_lines_and_generate_one_random_number(csv_file_path)\n",
    "random_number = random_number[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9127635f-5bea-46e8-a881-05484cc60289",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test_data['path'][random_number] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fd50a0db-6083-4da7-80d3-65681e985b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = \"./datasets/test_ne_np_female/Voice15.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "07021a6e-d452-4189-868c-3a2261e5add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = Wav2Vec2FeatureExtractor(\n",
    "    feature_size = 1, \n",
    "    sampling_rate = 16000, \n",
    "    padding_value = 0.0, \n",
    "    do_normalize = True, \n",
    "    return_attention_mask = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "882a3736-ac45-4591-93ed-43d8299b46a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_path = './input/cleaned-asr-data/data/vocabulary/vocab.json'\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\n",
    "    vocab_path, \n",
    "    unk_token = \"[UNK]\", \n",
    "    pad_token = \"[PAD]\", \n",
    "    word_delimiter_token = \"|\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c591684f-c985-406d-bab2-0318a07059d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor(\n",
    "    feature_extractor = feature_extractor, \n",
    "    tokenizer = tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "60f30d37-3ab4-41d7-a453-f976bbc8cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_speech(file):\n",
    "    speech_array, sampling_rate = torchaudio.load(file)\n",
    "    # print(speech_array,sampling_rate)\n",
    "    resampler = torchaudio.transforms.Resample(sampling_rate, 16000)\n",
    "    resampled_array = resampler(speech_array).squeeze()\n",
    "    if len(resampled_array.shape) == 1:\n",
    "        resampled_array = resampled_array.reshape([1,resampled_array.shape[0]])\n",
    "    # print(resampled_array.shape[1])\n",
    "    if resampled_array.shape[1] >= 200000:\n",
    "        # print('The input file is longer than 10 seconds')\n",
    "        list_of_segments = segmentLargeArray(resampled_array)\n",
    "        # print(list_of_segments)\n",
    "        output = ''\n",
    "        for segment in list_of_segments:\n",
    "            logits = model(segment.to(\"cuda\")).logits\n",
    "            pred_ids = torch.argmax(logits,dim=-1)[0]\n",
    "            output += processor.decode(pred_ids)\n",
    "        print(f\"Prediction:\\n{output}\")\n",
    "    else:\n",
    "        # print('The input file is less than 10 seconds')\n",
    "        logits = model(resampled_array.to(\"cuda\")).logits\n",
    "        # print(logits)\n",
    "        pred_ids = torch.argmax(logits, dim = -1)[0]\n",
    "        print(\"Prediction:\")\n",
    "        # print(processor.decode(pred_ids))\n",
    "    rdecoded_text = processor.decode(pred_ids)\n",
    "    return rdecoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c1a76406-651c-4e21-b7cf-2d29857f500f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "लागिसञ्चारकामाद्यमलेऔहमभूमीकाखेलेकोछपत्रपत्रिकाकोअभावमाव्यक्तितथाराष्ट्रलेराजनीतिखेलकुदकृषिरअन्यकुराहरूथापाउनसक्दैन[UNK][UNK]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from indicnlp.tokenize import indic_tokenize\n",
    "# predict_from_speech(test_audio_ip1)\n",
    "predicted_text = predict_from_speech(test1)\n",
    "predicted_text = predicted_text.replace(\"[UNK]\", \"\")\n",
    "\n",
    "def segment_text(text):\n",
    "    return ' '.join(indic_tokenize.trivial_tokenize(text))\n",
    "\n",
    "segmented_prediction = segment_text(predicted_text)\n",
    "print(segmented_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "24c7b42e-d4d9-4b58-9eeb-0ad4f847a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_from_csv(csv_filename, path_to_find):\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    label = df.loc[df['path'] == path_to_find, 'labels'].values[0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "98a3baf5-a6ac-46c5-acc1-47f2f6656a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = test_data['labels'][random_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "93835311-0e6d-469c-95e1-c17ff4c0995f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'पगनाथ दैलेख जिल्लाको एउटा गाविसको नाम'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "24628e7d-acca-4ee3-8cde-982f0d665908",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = pd.read_csv(\"E:/lipyantrak/datasets/archive/Nepali_Speech_To_Text_Dataset/transcripts/audio_transcript.csv\")\n",
    "ref = \"E:/lipyantrak/datasets/archive/Nepali_Speech_To_Text_Dataset/transcripts/audio_transcript.csv/2079-11-21_15.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e66c2381-d328-41fc-a0c5-580d08e20ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/lipyantrak/datasets/archive/Nepali_Speech_To_Text_Dataset/transcripts/audio_transcript.csv/2079-11-21_15.wav\n"
     ]
    }
   ],
   "source": [
    "# ref = get_label_from_csv(csv_file, path_to_find)\n",
    "print(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1336ec15-e85f-439a-aab6-a15982331979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "# Load the WER and CER metrics\n",
    "wer_metric = load(\"wer\")\n",
    "cer_metric = load(\"cer\")\n",
    "\n",
    "def compute_metrics(pred_text, ref_text):\n",
    "    \"\"\"\n",
    "    Computes WER and CER given predicted and reference texts.\n",
    "    \n",
    "    Args:\n",
    "        pred_text (str): The predicted transcription.\n",
    "        ref_text (str): The ground truth transcription.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with WER, CER, and adjusted CER (\"cer_best\").\n",
    "    \"\"\"\n",
    "    # Predictions and references should be lists of strings for the metrics\n",
    "    pred_str = [pred_text]  # Wrap in a list as required by the metric\n",
    "    ref_str = [ref_text]    # Wrap in a list as required by the metric\n",
    "\n",
    "    # Compute WER and CER\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=ref_str)\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=ref_str)\n",
    "\n",
    "    # Adjust CER for best model selection (optional logic)\n",
    "    # cer_best = 1 - cer\n",
    "\n",
    "    return {\"wer\": wer, \"cer\": cer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8ee7afce-b26a-43a5-a40e-f9d778787782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wer': 1.0, 'cer': 1.0}\n"
     ]
    }
   ],
   "source": [
    "pred_text = test1\n",
    "ref_text = ref\n",
    "# Compute WER and CER\n",
    "metrics = compute_metrics(pred_text, ref_text)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a91d94f-86f3-4d30-bea4-bc44a1c18cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
